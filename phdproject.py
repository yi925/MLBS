# -*- coding: utf-8 -*-
"""PhDproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iodo5JlgoqX4xhO2e7y3RZ8U2FdVyxIz
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
import statsmodels.formula.api as smf

"""## 資料前處理"""

url = 'https://github.com/kanra20/PhDSatisfaction/blob/main/Dataset/data2018.csv?raw=true'
df = pd.read_csv(url, index_col=0)

###selected variables
variables_list=['q1_1', 'q1_2', 'q1_3_1', 'q1_3_2', 'q1_3_3_r', 'q2_1', 'q2_2', 'q2_3_3', 'q2_4_1', 'q2_4_2', 'q2_5_1', 'q2_5_2', 'q2_6_1', 'q2_6_2', 'q2_7_1', 'q3_1', 'q4_1_1', 'q4_1_2', 'q4_1_3', 'q4_2_1', 'q4_2_2', 'q4_3', 'q4_4_1', 'q4_5']
df_new = df[variables_list]
df_new

#Rename the column names
new_column_names = {
    'q1_1': 'Gender',
    'q1_2': 'Age',
    'q1_3_1': 'MarriageStatus',
    'q1_3_2': 'IsMarried',
    'q1_3_3_r': 'MarriageChildStatus',
    'q2_1': 'EnterAge',
    'q2_2': 'GraduateAge',
    'q2_3_3': 'BreakFromSchool',
    'q2_4_1': 'InstitutionType',
    'q2_4_2': 'MasterPhDSchoolMatch',
    'q2_5_1': 'MajorField',
    'q2_5_2': 'MajorRelevance',
    'q2_6_1': 'WorkedOrNot',
    'q2_6_2': 'EmploymentStatus',
    'q2_7_1': 'PhDMotivation',
    'q3_1': 'ProgramSatisfaction', #y1
    'q4_1_1': 'CurrentJobStatus',
    'q4_1_2': 'JobType',
    'q4_1_3': 'JobObtain',
    'q4_2_1': 'CurrentInstitutionType',
    'q4_2_2': 'CurrentJobPosition',
    'q4_3': 'JobSatisfaction',
    'q4_4_1': 'CareerPlanMatch',
    'q4_5': 'DegreeBenefit' #y2
}

# Rename the columns
df_new.rename(columns = new_column_names, inplace=True)
print(df_new.head(5))

for column in df_new.columns:
    print(f"Column: {column}")
    print(df_new[column].unique())
    print("\n")

#把有N/A和沒有意見的資料刪掉，並把98替換成0（表示沒有工作）
df_new_cleaned = df_new[(df_new != 99).all(axis=1) & (df_new != 999).all(axis=1)]
df_new_cleaned = df_new_cleaned[(df_new_cleaned['ProgramSatisfaction'] != 6) & (df_new_cleaned['JobSatisfaction'] != 6) & (df_new_cleaned['DegreeBenefit'] != 6)]
df_new_cleaned = df_new_cleaned.replace(98, 0)

#把滿意度和效益的數值反過來（5表示非常滿意，1表示非常不滿意）
mapping = {1: 5, 2: 4, 3: 3, 4: 2, 5: 1}
df_new_cleaned['ProgramSatisfaction'] = df_new_cleaned['ProgramSatisfaction'].replace(mapping)
df_new_cleaned['JobSatisfaction'] = df_new_cleaned['JobSatisfaction'].replace(mapping)
df_new_cleaned['DegreeBenefit'] = df_new_cleaned['DegreeBenefit'].replace(mapping)

for column in df_new_cleaned.columns:
    print(f"Column: {column}")
    print(df_new_cleaned[column].unique())
    print("\n")

y1 = df_new_cleaned['ProgramSatisfaction']
y2 = df_new_cleaned['DegreeBenefit']

X = df_new_cleaned.drop(['ProgramSatisfaction', 'DegreeBenefit'], axis = 1)
X

X1=X.drop(['CurrentJobStatus','JobType','JobObtain','CurrentInstitutionType','CurrentJobPosition','JobSatisfaction','CareerPlanMatch'],axis=1)
X1

X2=X.drop(['MarriageStatus',
        'IsMarried',
        'MarriageChildStatus',
        'EnterAge',
        'GraduateAge',
        'BreakFromSchool',
        'InstitutionType',
        'MasterPhDSchoolMatch',
        'MajorField',
        'MajorRelevance',
        'WorkedOrNot',
        'EmploymentStatus',
        'PhDMotivation'],axis=1)
X2

"""## 拆測試訓練集"""

from sklearn.model_selection import train_test_split

X_train, X_test, y1_train, y1_test = train_test_split(
    X, y1,
    test_size = .25,
    random_state = 48,
    stratify = y1)

X_train, X_test, y2_train, y2_test = train_test_split(
    X, y2,
    test_size = .25,
    random_state = 48,
    stratify = y2)

"""## Linear Regression"""

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LinearRegression

#設定類別變項onehotencoding的transformer
transformer = ColumnTransformer(
    transformers = [
        ("cat_transformer",
         OneHotEncoder(
             sparse_output = False,
             drop = "first"),
         ['Gender', 'Age', 'MarriageStatus', 'IsMarried', 'MarriageChildStatus', 'EnterAge', 'GraduateAge',
          'BreakFromSchool', 'InstitutionType', 'MasterPhDSchoolMatch', 'MajorField', 'MajorRelevance',
          'WorkedOrNot', 'EmploymentStatus', 'PhDMotivation', 'CurrentJobStatus', 'JobType', 'JobObtain',
          'CurrentInstitutionType', 'CurrentJobPosition', 'CareerPlanMatch'])],
       remainder = 'passthrough')

#建立linear regression的pipeline
lr_pipeline = Pipeline(
    steps=[("transformer",
            transformer),
           ("estimator",
            LinearRegression())])
lr_pipeline

"""### 預測博士學位滿意度"""

#fit模型
lr_pipeline_y1 = lr_pipeline.fit(X_train, y1_train)

#評估表現
from sklearn.metrics import r2_score, mean_squared_error
print('R^2 on Training Set: %.2f' %
      r2_score(
          y1_train,
          lr_pipeline_y1.predict(
              X_train)))
print('R^2 on Test Set: %.2f' %
      r2_score(
          y1_test,
          lr_pipeline_y1.predict(
              X_test)))

#建立MSE scorer
from sklearn.metrics import make_scorer
mse_scorer = make_scorer(
    mean_squared_error,
    greater_is_better = False)

#將feature name取出
feature_names = lr_pipeline_y1["transformer"].get_feature_names_out()
feature_names = [
    feature_name.split("__")[-1]
    for feature_name in feature_names]

#迴歸係數的圖
plt.figure(figsize = (32, 8))
_ = pd.Series(
    lr_pipeline_y1["estimator"].coef_,
    index = feature_names).plot.bar(
    rot = 70)

#特徵重要性的圖
from sklearn.inspection import permutation_importance
lr_pfi_sklearn_y1 = permutation_importance(
    lr_pipeline_y1,
    X_test,
    y1_test,
    scoring = mse_scorer,
    n_repeats = 100, #B
    random_state = 48)
_ = pd.Series(
    lr_pfi_sklearn_y1.importances_mean,
    index = X.columns).plot.bar(rot = 70)

"""### 預測博士學位效益"""

#fit模型
lr_pipeline_y2 = lr_pipeline.fit(X_train, y2_train)

#評估表現
print('R^2 on Training Set: %.2f' %
      r2_score(
          y2_train,
          lr_pipeline_y2.predict(
              X_train)))
print('R^2 on Test Set: %.2f' %
      r2_score(
          y2_test,
          lr_pipeline_y2.predict(
              X_test)))

#迴歸係數的圖
plt.figure(figsize = (32, 8))
_ = pd.Series(
    lr_pipeline_y2["estimator"].coef_,
    index = feature_names).plot.bar(
    rot = 70)

#特徵重要性的圖
lr_pfi_sklearn_y2 = permutation_importance(
    lr_pipeline_y2,
    X_test,
    y2_test,
    scoring = mse_scorer,
    n_repeats = 100, #B
    random_state = 48)
_ = pd.Series(
    lr_pfi_sklearn_y2.importances_mean,
    index = X.columns).plot.bar(rot = 70)

"""## 用了LASSO / Ridge的linear regression

### LASSO
"""

#建立ridge estimator、pipeline及參數範圍
from sklearn.linear_model import Lasso
lasso_pipeline = Pipeline(
    steps = [
        ("transformer",
         transformer),
        ("estimator",
         Lasso(
            max_iter=10000,
            warm_start=True))])

lasso_param_grid = {
    "estimator__alpha":np.logspace(-.01, -4, 100)}

#建立5折的splitter
from sklearn.model_selection import KFold
splitter = KFold(
    n_splits = 5,
    shuffle = True,
    random_state = 48)

#進行參數挑選並fit挑選出的模型
from sklearn.model_selection import GridSearchCV
lasso_searcher = GridSearchCV(
    estimator = lasso_pipeline,
    param_grid = lasso_param_grid,
    scoring = 'r2',
    refit = True,
    cv = splitter)

"""### 預測學位滿意度"""

lasso_searcher_y1 = lasso_searcher.fit(X_train, y1_train)

lasso_searcher_y1.best_params_

lasso_searcher_y1.best_score_

best_lasso_estimator_y1 = lasso_searcher_y1.best_estimator_
print("R^2 on Training Data: %.3f" %
      r2_score(
          y1_train,
          best_lasso_estimator_y1.predict(X_train)))
print("R^2 on Testing Data: %.3f" %
      r2_score(
          y1_test,
          best_lasso_estimator_y1.predict(X_test)))

#迴歸係數的圖（畫不出來）
plt.figure(figsize = (32, 8))
_ = pd.Series(
    best_lasso_estimator_y1['estimator'].coef_,
    index = feature_names).plot.bar(
    rot = 70)

#畫特徵重要性的圖（畫不出來）
lasso_pfi_sklearn_y1 = permutation_importance(
    best_lasso_estimator_y1,
    X_test,
    y1_test,
    scoring = mse_scorer,
    n_repeats = 100, #B
    random_state = 48)
_ = pd.Series(
    lasso_pfi_sklearn_y1.importances_mean,
    index = X.columns).plot.bar(rot = 70)

"""### 預測學位效益"""

lasso_searcher_y2 = lasso_searcher.fit(X_train, y2_train)

lasso_searcher_y2.best_params_

lasso_searcher_y2.best_score_

#評估表現
best_lasso_estimator_y2 = lasso_searcher_y1.best_estimator_
print("R^2 on Training Data: %.3f" %
      r2_score(
          y2_train,
          best_lasso_estimator_y2.predict(X_train)))
print("R^2 on Testing Data: %.3f" %
      r2_score(
          y2_test,
          best_lasso_estimator_y2.predict(X_test)))

#迴歸係數的圖（畫不出來）
plt.figure(figsize = (32, 8))
_ = pd.Series(
    best_lasso_estimator_y2['estimator'].coef_,
    index = feature_names).plot.bar(
    rot = 70)

#畫特徵重要性的圖（畫不出來）
lasso_pfi_sklearn_y2 = permutation_importance(
    best_lasso_estimator_y2,
    X_test,
    y2_test,
    scoring = mse_scorer,
    n_repeats = 100, #B
    random_state = 48)
_ = pd.Series(
    lasso_pfi_sklearn_y2.importances_mean,
    index = X.columns).plot.bar(rot = 70)

"""### Ridge"""

#建立ridge estimator、pipeline及參數範圍
from sklearn.linear_model import Ridge
ridge_pipeline = Pipeline(
    steps = [
        ("transformer",
         transformer),
        ("estimator",
         Ridge(
            max_iter = 10000))])

ridge_param_grid = {
    "estimator__alpha":np.logspace(-.01, -4, 100)}

#進行參數挑選
ridge_searcher = GridSearchCV(
    estimator = ridge_pipeline,
    param_grid = ridge_param_grid,
    scoring = 'r2', #也可直接打scoring = "r2"
    refit = True,
    cv = splitter)

"""### 預測學位滿意度"""

ridge_searcher_y1 = ridge_searcher.fit(X_train, y1_train)

ridge_searcher_y1.best_params_

ridge_searcher_y1.best_score_

#評估表現
best_ridge_estimator_y1 = ridge_searcher_y1.best_estimator_
print("R^2 on Training Data: %.3f" %
      r2_score(
          y1_train,
          best_ridge_estimator_y1.predict(X_train)))
print("R^2 on Testing Data: %.3f" %
      r2_score(
          y1_test,
          best_ridge_estimator_y1.predict(X_test)))

#迴歸係數的圖
plt.figure(figsize = (32, 8))
_ = pd.Series(
    best_ridge_estimator_y1['estimator'].coef_,
    index = feature_names).plot.bar(
    rot = 70)

#畫特徵重要性的圖
ridge_pfi_sklearn_y1 = permutation_importance(
    best_ridge_estimator_y1,
    X_test,
    y1_test,
    scoring = mse_scorer,
    n_repeats = 100, #B
    random_state = 48)
_ = pd.Series(
    ridge_pfi_sklearn_y1.importances_mean,
    index = X.columns).plot.bar(rot = 70)

"""### 預測學位效益"""

ridge_searcher_y2 = ridge_searcher.fit(X_train, y2_train)

ridge_searcher_y2.best_params_

ridge_searcher_y2.best_score_

#評估表現
best_ridge_estimator_y2 = ridge_searcher_y2.best_estimator_
print("R^2 on Training Data: %.3f" %
      r2_score(
          y2_train,
          best_ridge_estimator_y2.predict(X_train)))
print("R^2 on Testing Data: %.3f" %
      r2_score(
          y2_test,
          best_ridge_estimator_y2.predict(X_test)))

#迴歸係數的圖
plt.figure(figsize = (32, 8))
_ = pd.Series(
    best_ridge_estimator_y2['estimator'].coef_,
    index = feature_names).plot.bar(
    rot = 70)

#畫特徵重要性的圖
ridge_pfi_sklearn_y2 = permutation_importance(
    best_ridge_estimator_y2,
    X_test,
    y2_test,
    scoring = mse_scorer,
    n_repeats = 100, #B
    random_state = 48)
_ = pd.Series(
    ridge_pfi_sklearn_y2.importances_mean,
    index = X.columns).plot.bar(rot = 70)

"""## KNN"""

#建立estimator和pipeline
from sklearn.neighbors import KNeighborsRegressor
knn_pipeline = Pipeline(
    steps = [
        ("transformer",
         transformer),
        ("estimator",
         KNeighborsRegressor(
             weights = "uniform",
             algorithm = "auto"))])
knn_pipeline

#設定KNN參數並進行挑選
knn_param_grid = {
    "estimator__n_neighbors":np.arange(1, 50, 2)}

knn_searcher = GridSearchCV(
    estimator = knn_pipeline,
    param_grid = knn_param_grid,
    scoring = mse_scorer,
    refit = True,
    cv = splitter)

"""### 預測博士學位滿意度"""

#fit模型
knn_searcher_y1 = knn_searcher.fit(X_train, y1_train)

#用挑選出的最佳模型進行預測並評估模型表現
best_knn_estimator_y1 = knn_searcher_y1.best_estimator_
print("MSE on Training Data: %.3f" %
      mean_squared_error(
          y1_train,
          best_knn_estimator_y1.predict(X_train)))
print("MSE on Test Data: %.3f" %
      mean_squared_error(
          y1_test,
          best_knn_estimator_y1.predict(X_test)))
print("R^2 on Training Data: %.3f" %
      r2_score(
          y1_train,
          best_knn_estimator_y1.predict(X_train)))
print("R^2 on Test Data: %.3f" %
      r2_score(
          y1_test,
          best_knn_estimator_y1.predict(X_test)))

#畫特徵重要性的圖
knn_pfi_sklearn_y1 = permutation_importance(
    best_knn_estimator_y1,
    X_test,
    y1_test,
    scoring = mse_scorer,
    n_repeats = 100, #B
    random_state = 48)
_ = pd.Series(
    knn_pfi_sklearn_y1.importances_mean,
    index = X.columns).plot.bar(rot = 70)

"""### 預測博士學位效益"""

#fit模型
knn_searcher_y2 = knn_searcher.fit(X_train, y1_train)

#用挑選出的最佳模型進行預測並評估模型表現
best_knn_estimator_y2 = knn_searcher_y2.best_estimator_
print("MSE on Training Data: %.3f" %
      mean_squared_error(
          y2_train,
          best_knn_estimator_y2.predict(X_train)))
print("MSE on Test Data: %.3f" %
      mean_squared_error(
          y2_test,
          best_knn_estimator_y2.predict(X_test)))
print("R^2 on Training Data: %.3f" %
      r2_score(
          y2_train,
          best_knn_estimator_y2.predict(X_train)))
print("R^2 on Test Data: %.3f" %
      r2_score(
          y2_test,
          best_knn_estimator_y2.predict(X_test)))

#畫特徵重要性的圖
knn_pfi_sklearn_y2 = permutation_importance(
    best_knn_estimator_y2,
    X_test,
    y2_test,
    scoring = mse_scorer,
    n_repeats = 100, #B
    random_state = 48)
_ = pd.Series(
    knn_pfi_sklearn_y2.importances_mean,
    index = X.columns).plot.bar(rot = 70)

"""## Decision Tree"""

from sklearn.tree import DecisionTreeRegressor

#建立estimator
dt_estimator = DecisionTreeRegressor(
    criterion = 'squared_error',
    ccp_alpha = 0.015)

#建立pipeline
dt_pipeline = Pipeline(
    steps=[("transformer",
            transformer),
           ("estimator",
            dt_estimator)])

"""### 預測學位滿意度"""

#fit模型
dt_pipeline_y1 = dt_pipeline.fit(X_train, y1_train)

#評估模型表現
print("R^2 on Training Data: %.3f" %
      r2_score(
          y1_train,
          dt_pipeline_y1.predict(X_train)))
print("R^2 on Test Data: %.3f" %
      r2_score(
          y1_test,
          dt_pipeline_y1.predict(X_test)))
print("MSE on Training Data: %.3f" %
      mean_squared_error(
          y1_train,
          dt_pipeline_y1.predict(X_train)))
print("MSE on Test Data: %.3f" %
      mean_squared_error(
          y1_test,
          dt_pipeline_y1.predict(X_test)))

#畫特徵重要性的圖（畫不出來）
dt_pfi_sklearn_y1 = permutation_importance(
    dt_pipeline_y1,
    X_test,
    y1_test,
    scoring = mse_scorer,
    n_repeats = 100, #B
    random_state = 48)
_ = pd.Series(
    dt_pfi_sklearn_y1.importances_mean,
    index = X.columns).plot.bar(rot = 70)

#畫流程圖（畫不出來）
transformed_feature_names = dt_pipeline_y1[
    "transformer"].get_feature_names_out()
transformed_feature_names = [
    transformed_feature_name.split("__")[-1]
    for transformed_feature_name in transformed_feature_names]

from sklearn.tree import plot_tree
plt.figure(figsize = (8, 6))
_ = plot_tree(
    dt_pipeline_y1["estimator"],
    feature_names = transformed_feature_names,
    filled = True)

"""### 預測學位效益"""

#fit模型
dt_pipeline_y2 = dt_pipeline.fit(X_train, y2_train)

#評估模型表現
print("R^2 on Training Data: %.3f" %
      r2_score(
          y2_train,
          dt_pipeline_y2.predict(X_train)))
print("R^2 on Test Data: %.3f" %
      r2_score(
          y2_test,
          dt_pipeline_y2.predict(X_test)))
print("MSE on Training Data: %.3f" %
      mean_squared_error(
          y2_train,
          dt_pipeline_y2.predict(X_train)))
print("MSE on Test Data: %.3f" %
      mean_squared_error(
          y2_test,
          dt_pipeline_y2.predict(X_test)))

#畫特徵重要性的圖
dt_pfi_sklearn_y2 = permutation_importance(
    dt_pipeline_y2,
    X_test,
    y2_test,
    scoring = mse_scorer,
    n_repeats = 100, #B
    random_state = 48)
_ = pd.Series(
    dt_pfi_sklearn_y2.importances_mean,
    index = X.columns).plot.bar(rot = 70)

#畫流程圖
transformed_feature_names = dt_pipeline_y2[
    "transformer"].get_feature_names_out()
transformed_feature_names = [
    transformed_feature_name.split("__")[-1]
    for transformed_feature_name in transformed_feature_names]

plt.figure(figsize = (8, 6))
_ = plot_tree(
    dt_pipeline_y2["estimator"],
    feature_names = transformed_feature_names,
    filled = True)

"""## 有進行修剪的tree"""

#設定參數進行挑選
dt_param_grid = {
    "estimator__ccp_alpha":np.linspace(0, .1, 100)}

dt_searcher = GridSearchCV(
    estimator = dt_pipeline,
    param_grid = dt_param_grid,
    scoring = 'r2',
    refit = True,
    cv = splitter)

"""### 預測學位滿意度"""

#fit模型
dt_searcher_y1 = dt_searcher.fit(X_train, y1_train)

#用挑選出的最佳參數進行預測並評估模型表現
best_dt_pipeline_y1 = dt_searcher_y1.best_estimator_
y1_pred_train = best_dt_pipeline_y1.predict(X_train)
y1_pred_test = best_dt_pipeline_y1.predict(X_test)

print("R^2 on Training Set: %.3f" %
      r2_score(
          y1_train,
          y1_pred_train))
print("R^2 on Test Set: %.3f" %
      r2_score(
          y1_test,
          y1_pred_test))
print("MSE on Training Data: %.3f" %
      mean_squared_error(
          y1_train,
          y1_pred_train))
print("MSE on Test Data: %.3f" %
      mean_squared_error(
          y1_test,
          y1_pred_test))

#畫特徵重要性的圖
dt_pfi_sklearn_y1 = permutation_importance(
    best_dt_pipeline_y1,
    X_test,
    y1_test,
    scoring = mse_scorer,
    n_repeats = 100, #B
    random_state = 48)
_ = pd.Series(
    dt_pfi_sklearn_y1.importances_mean,
    index = X.columns).plot.bar(rot = 70)

"""### 預測學位效益"""

#fit模型
dt_searcher_y2 = dt_searcher.fit(X_train, y2_train)

#用挑選出的最佳參數進行預測並評估模型表現
best_dt_pipeline_y2 = dt_searcher_y2.best_estimator_
y2_pred_train = best_dt_pipeline_y2.predict(X_train)
y2_pred_test = best_dt_pipeline_y2.predict(X_test)

print("R^2 on Training Set: %.3f" %
      r2_score(
          y2_train,
          y2_pred_train))
print("R^2 on Test Set: %.3f" %
      r2_score(
          y2_test,
          y2_pred_test))
print("MSE on Training Data: %.3f" %
      mean_squared_error(
          y2_train,
          y2_pred_train))
print("MSE on Test Data: %.3f" %
      mean_squared_error(
          y2_test,
          y2_pred_test))

#畫特徵重要性的圖
dt_pfi_sklearn_y2 = permutation_importance(
    best_dt_pipeline_y2,
    X_test,
    y2_test,
    scoring = mse_scorer,
    n_repeats = 100, #B
    random_state = 48)
_ = pd.Series(
    dt_pfi_sklearn_y2.importances_mean,
    index = X.columns).plot.bar(rot = 70)

"""## Random forest"""

#建立estimator和pipeline
from sklearn.ensemble import RandomForestRegressor
rf_estimator = RandomForestRegressor(
    n_estimators = 500,
    criterion = "squared_error",
    max_features = "sqrt",
    random_state = 48)

rf_pipeline = Pipeline(
    steps=[("transformer",
            transformer),
           ("estimator",
            rf_estimator)])

"""### 預測學位滿意度"""

#fit模型並進行預測
rf_pipeline_y1 = rf_pipeline.fit(X_train, y1_train)

y1_pred_train = rf_pipeline_y1.predict(X_train)
y1_pred_test = rf_pipeline_y1.predict(X_test)

#評估表現
print("R^2 on Training Set: %.3f" %
      r2_score(
          y1_train,
          y1_pred_train))
print("R^2 on Test Set: %.3f" %
      r2_score(
          y1_test,
          y1_pred_test))
print("MSE on Training Data: %.3f" %
      mean_squared_error(
          y1_train,
          y1_pred_train))
print("MSE on Test Data: %.3f" %
      mean_squared_error(
          y1_test,
          y1_pred_test))

#畫特徵重要性圖
rf_pfi_y1 = permutation_importance(
    rf_pipeline_y1,
    X_test,
    y1_test,
    scoring = mse_scorer,
    n_repeats = 100,
    random_state = 48)
plt.figure(figsize = (6, 6))
_ = pd.Series(
    rf_pfi_y1.importances_mean,
    index = X.columns).iloc[::-1].plot.barh()

"""### 預測學位效益"""

#fit模型並進行預測
rf_pipeline_y2 = rf_pipeline.fit(X_train, y2_train)

y2_pred_train = rf_pipeline_y2.predict(X_train)
y2_pred_test = rf_pipeline_y2.predict(X_test)

#評估表現
print("R^2 on Training Set: %.3f" %
      r2_score(
          y2_train,
          y2_pred_train))
print("R^2 on Test Set: %.3f" %
      r2_score(
          y2_test,
          y2_pred_test))
print("MSE on Training Data: %.3f" %
      mean_squared_error(
          y2_train,
          y2_pred_train))
print("MSE on Test Data: %.3f" %
      mean_squared_error(
          y2_test,
          y2_pred_test))

#畫特徵重要性圖
rf_pfi_y2 = permutation_importance(
    rf_pipeline_y2,
    X_test,
    y2_test,
    scoring = mse_scorer,
    n_repeats = 100,
    random_state = 48)
plt.figure(figsize = (6, 6))
_ = pd.Series(
    rf_pfi_y2.importances_mean,
    index = X.columns).iloc[::-1].plot.barh()

